---

psql_dump_path: /var/postgresql_dumps
mongo_dump_path: /var/mongodb_dumps
arteria_dump_path: /var/arteria_dumps

## Configure Stackstorm

st2_version: 2.0.1
st2_revision: 3
st2web_revision: 2
mistral_version: 2.0.1-3

st2_system_user_in_sudoers: no

postgresql_logging_collector: on
postgresql_log_directory: /var/log/postgresql
postgresql_max_connections: 1000

stackstorm_token_ttl: 604800 # 1 week in seconds

## Configure Arteria

arteria_packs_version: v2.9.2

# Remote systems 
nestor_remote_path: [path on a remote legacy hpc cluster for data uploads]
irma_remote_path: [path on an active hpc cluster for data uploads]
irma_reports_remote_path: [path on an active hpc cluster where reports are kept]
ngi_pipeline_url: [url to start a pipeline on a remote hpc cluster]

irma_checksum_base_url: [url to checksum service running on remote hpc cluster]
irma_siswrap_base_url: [url to siswrap service running on remote hpc cluster]
irma_delivery_service_url: [url to delivery service running on remote hpc cluster]

# List of hosts where we need to verify SSH CA certs. Bit of a hack atm. 
arteria_nodes: "biotank5,biotank6,biotank7,biotank8,biotank9,biotank10,biotank11,biotank12,biotank13,biotank14"

hermes_base_url: [url to internal web service that will give us a samplesheet for a certain runfolder]
hermes_user: [username in cleartext for the samplesheet web service]

summary_host: [host name where we keep statistics of runs]
summary_destination: [path to general statistics data]
summary_ngi_pipeline_reports_destination: [path to specific kind of statistics data]

remote_host: [hostname for a remote legacy hpc cluster]
remote_host_key: [ssh key to use when logging in to the legacy system]
remote_destination: [path on legacy hpc cluster where uploads are stored]

remote_sisyphus_location: [path on legacy hpc cluster where sisyphus sw is stored, to be run by remote command from workflow]

charon_base_url: [url to statistics web service]

# Slack channels for info/err/warn msg 
charon_status_report_slack_channel: "#charon_reports"
check_cert_slack_channel: "#arteria-ops"
delivery_workflow_status_slack_channel: '#arteria-ops'

supr_api_url: [url to web service that handles metadata concerning projects for data delivery]
supr_api_user: [username in clear text]


## TSM based backups to remote system 

# String of file paths to exclude from the compressed archive (egrep syntax). 
#
pdc_archive_excludes: "^Config|^InterOp|^SampleSheet.csv|^Unaligned|^runParameters.xml|^RunInfo.xml"

# Number of fastq files to expect when creating archive. If we find less files than this
# then the action will fail.
pdc_archive_fastq_threshold: 1
pdc_archive_python_path: /opt/arteria/arteria-runfolder-env/bin/python
pdc_archive_exclude_links: "-e Data -e Thumbnail_Images"
